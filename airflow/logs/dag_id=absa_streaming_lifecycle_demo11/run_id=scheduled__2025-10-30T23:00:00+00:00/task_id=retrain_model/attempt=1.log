[2025-10-31T07:41:23.920+0700] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-10-31T07:41:23.944+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-30T23:00:00+00:00 [queued]>
[2025-10-31T07:41:23.949+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-30T23:00:00+00:00 [queued]>
[2025-10-31T07:41:23.949+0700] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-10-31T07:41:23.958+0700] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): retrain_model> on 2025-10-30 23:00:00+00:00
[2025-10-31T07:41:23.967+0700] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=9369) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-10-31T07:41:23.968+0700] {standard_task_runner.py:63} INFO - Started process 9374 to run task
[2025-10-31T07:41:23.968+0700] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'absa_streaming_lifecycle_demo11', 'retrain_model', 'scheduled__2025-10-30T23:00:00+00:00', '--job-id', '17', '--raw', '--subdir', 'DAGS_FOLDER/absa_streaming_lifecycle_dag1.py', '--cfg-path', '/tmp/tmpdezbo__5']
[2025-10-31T07:41:23.970+0700] {standard_task_runner.py:91} INFO - Job 17: Subtask retrain_model
[2025-10-31T07:41:24.005+0700] {task_command.py:426} INFO - Running <TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-30T23:00:00+00:00 [running]> on host b701d4cdc1cf
[2025-10-31T07:41:24.066+0700] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='absa_streaming_lifecycle_demo11' AIRFLOW_CTX_TASK_ID='retrain_model' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T23:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T23:00:00+00:00'
[2025-10-31T07:41:24.068+0700] {taskinstance.py:430} INFO - ::endgroup::
[2025-10-31T07:41:24.069+0700] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T07:41:24.069+0700] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'bash -c "set -euo pipefail; python /opt/***/projects/absa_streaming/scripts/retrain.py"']
[2025-10-31T07:41:24.085+0700] {subprocess.py:86} INFO - Output:
[2025-10-31T07:41:38.026+0700] {subprocess.py:93} INFO - /home/***/.local/lib/python3.12/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
[2025-10-31T07:41:38.027+0700] {subprocess.py:93} INFO -   warnings.warn(
[2025-10-31T07:43:52.976+0700] {subprocess.py:93} INFO - /opt/***/projects/absa_streaming/scripts/retrain.py:423: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
[2025-10-31T07:43:52.978+0700] {subprocess.py:93} INFO -   "saved_at": datetime.utcnow().isoformat(),
[2025-10-31T07:43:53.307+0700] {subprocess.py:93} INFO - ==> Kh·ªüi ƒë·ªông retrain.py (train=TRAIN; VAL ch·ªâ h·ªó tr·ª£; quy·∫øt ƒë·ªãnh d·ª±a tr√™n TEST cu·ªëi).
[2025-10-31T07:43:53.308+0700] {subprocess.py:93} INFO - [Info] F1_macro t·ªët nh·∫•t ƒë√£ log: 0.0000
[2025-10-31T07:43:53.308+0700] {subprocess.py:93} INFO - [Info] VAL: /opt/***/projects/absa_streaming/data/val_data.csv (rows=936)
[2025-10-31T07:43:53.308+0700] {subprocess.py:93} INFO - [INFO] PostgreSQL r·ªóng ‚Äî ch∆∞a c√≥ model retrain n√†o, d√πng model m·∫∑c ƒë·ªãnh.
[2025-10-31T07:43:53.308+0700] {subprocess.py:93} INFO - [INFO] üîÅ D√πng model m·∫∑c ƒë·ªãnh: /opt/***/models/best_absa_hardshare.pt
[2025-10-31T07:43:53.308+0700] {subprocess.py:93} INFO - [INFO] Model ƒëang train tr√™n thi·∫øt b·ªã: cuda
[2025-10-31T07:43:53.309+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T07:43:53.309+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T07:43:53.309+0700] {subprocess.py:93} INFO - [Epoch 2] time=32.8s | train_loss=0.0438 | VAL: loss=0.0228 acc=0.9995 f1_macro=0.3332 pre_macro=0.3333 rec_macro=0.3332
[2025-10-31T07:43:53.309+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T07:43:53.309+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T07:43:53.309+0700] {subprocess.py:93} INFO - [Epoch 4] time=31.3s | train_loss=0.0040 | VAL: loss=0.0027 acc=1.0000 f1_macro=1.0000 pre_macro=1.0000 rec_macro=1.0000
[2025-10-31T07:43:53.309+0700] {subprocess.py:93} INFO - [FINAL TEST] loss=0.0025 | acc=1.0000 | f1_macro=1.0000 | pre_macro=1.0000 | rec_macro=1.0000
[2025-10-31T07:43:53.309+0700] {subprocess.py:93} INFO - [SAVE] B·∫Øt ƒë·∫ßu l∆∞u model v√†o: /opt/***/models/newer_models/best_absa_2/model.pt
[2025-10-31T07:43:53.310+0700] {subprocess.py:93} INFO - [SAVE] ƒê√£ l∆∞u file .pt v√† .json th√†nh c√¥ng.
[2025-10-31T07:43:53.310+0700] {subprocess.py:93} INFO - [SAVE] TEST f1_macro improved (0.0000 -> 1.0000). ƒê√£ c·∫≠p nh·∫≠t DB. Saved to: /opt/***/models/newer_models/best_absa_2
[2025-10-31T07:43:53.310+0700] {subprocess.py:93} INFO - ==> Retrain ho√†n t·∫•t.
[2025-10-31T07:43:54.365+0700] {subprocess.py:97} INFO - Command exited with return code 0
[2025-10-31T07:43:54.368+0700] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-10-31T07:43:54.412+0700] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=absa_streaming_lifecycle_demo11, task_id=retrain_model, execution_date=20251030T230000, start_date=20251031T004123, end_date=20251031T004354
[2025-10-31T07:43:54.471+0700] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-10-31T07:43:54.593+0700] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T07:43:54.595+0700] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-10-31T07:55:33.269+0700] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-10-31T07:55:33.289+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-30T23:00:00+00:00 [queued]>
[2025-10-31T07:55:33.296+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-30T23:00:00+00:00 [queued]>
[2025-10-31T07:55:33.296+0700] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-10-31T07:55:33.309+0700] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): retrain_model> on 2025-10-30 23:00:00+00:00
[2025-10-31T07:55:33.321+0700] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=12067) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-10-31T07:55:33.323+0700] {standard_task_runner.py:63} INFO - Started process 12071 to run task
[2025-10-31T07:55:33.323+0700] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'absa_streaming_lifecycle_demo11', 'retrain_model', 'scheduled__2025-10-30T23:00:00+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/absa_streaming_lifecycle_dag1.py', '--cfg-path', '/tmp/tmpgtf1od8e']
[2025-10-31T07:55:33.326+0700] {standard_task_runner.py:91} INFO - Job 21: Subtask retrain_model
[2025-10-31T07:55:33.368+0700] {task_command.py:426} INFO - Running <TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-30T23:00:00+00:00 [running]> on host b701d4cdc1cf
[2025-10-31T07:55:33.439+0700] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='absa_streaming_lifecycle_demo11' AIRFLOW_CTX_TASK_ID='retrain_model' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T23:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T23:00:00+00:00'
[2025-10-31T07:55:33.441+0700] {taskinstance.py:430} INFO - ::endgroup::
[2025-10-31T07:55:33.441+0700] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T07:55:33.442+0700] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'bash -c "set -euo pipefail; python /opt/***/projects/absa_streaming/scripts/retrain.py"']
[2025-10-31T07:55:33.455+0700] {subprocess.py:86} INFO - Output:
[2025-10-31T07:55:44.729+0700] {subprocess.py:93} INFO - /home/***/.local/lib/python3.12/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
[2025-10-31T07:55:44.730+0700] {subprocess.py:93} INFO -   warnings.warn(
[2025-10-31T07:58:03.602+0700] {subprocess.py:93} INFO - /opt/***/projects/absa_streaming/scripts/retrain.py:423: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
[2025-10-31T07:58:03.660+0700] {subprocess.py:93} INFO -   "saved_at": datetime.utcnow().isoformat(),
[2025-10-31T07:58:03.947+0700] {subprocess.py:93} INFO - ==> Kh·ªüi ƒë·ªông retrain.py (train=TRAIN; VAL ch·ªâ h·ªó tr·ª£; quy·∫øt ƒë·ªãnh d·ª±a tr√™n TEST cu·ªëi).
[2025-10-31T07:58:03.949+0700] {subprocess.py:93} INFO - [Info] F1_macro t·ªët nh·∫•t ƒë√£ log: 0.0000
[2025-10-31T07:58:03.950+0700] {subprocess.py:93} INFO - [Info] VAL: /opt/***/projects/absa_streaming/data/val_data.csv (rows=936)
[2025-10-31T07:58:03.951+0700] {subprocess.py:93} INFO - [INFO] PostgreSQL r·ªóng ‚Äî ch∆∞a c√≥ model retrain n√†o, d√πng model m·∫∑c ƒë·ªãnh.
[2025-10-31T07:58:03.953+0700] {subprocess.py:93} INFO - [INFO] üîÅ D√πng model m·∫∑c ƒë·ªãnh: /opt/***/models/best_absa_hardshare.pt
[2025-10-31T07:58:03.955+0700] {subprocess.py:93} INFO - [INFO] Model ƒëang train tr√™n thi·∫øt b·ªã: cuda
[2025-10-31T07:58:03.957+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T07:58:03.958+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T07:58:03.959+0700] {subprocess.py:93} INFO - [Epoch 2] time=31.4s | train_loss=0.0435 | VAL: loss=0.0227 acc=0.9995 f1_macro=0.3332 pre_macro=0.3333 rec_macro=0.3332
[2025-10-31T07:58:03.960+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T07:58:03.960+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T07:58:03.960+0700] {subprocess.py:93} INFO - [Epoch 4] time=32.7s | train_loss=0.0040 | VAL: loss=0.0027 acc=1.0000 f1_macro=1.0000 pre_macro=1.0000 rec_macro=1.0000
[2025-10-31T07:58:03.961+0700] {subprocess.py:93} INFO - [FINAL TEST] loss=0.0024 | acc=1.0000 | f1_macro=1.0000 | pre_macro=1.0000 | rec_macro=1.0000
[2025-10-31T07:58:03.961+0700] {subprocess.py:93} INFO - [SAVE] B·∫Øt ƒë·∫ßu l∆∞u model v√†o: /opt/***/models/newer_models/best_absa_2/model.pt
[2025-10-31T07:58:03.962+0700] {subprocess.py:93} INFO - [SAVE] ƒê√£ l∆∞u file .pt v√† .json th√†nh c√¥ng.
[2025-10-31T07:58:03.963+0700] {subprocess.py:93} INFO - [SAVE] TEST f1_macro improved (0.0000 -> 1.0000). ƒê√£ c·∫≠p nh·∫≠t DB. Saved to: /opt/***/models/newer_models/best_absa_2
[2025-10-31T07:58:03.965+0700] {subprocess.py:93} INFO - ==> Retrain ho√†n t·∫•t.
[2025-10-31T07:58:05.586+0700] {subprocess.py:97} INFO - Command exited with return code 0
[2025-10-31T07:58:05.605+0700] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-10-31T07:58:05.932+0700] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=absa_streaming_lifecycle_demo11, task_id=retrain_model, execution_date=20251030T230000, start_date=20251031T005533, end_date=20251031T005805
[2025-10-31T07:58:06.072+0700] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-10-31T07:58:06.291+0700] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T07:58:06.293+0700] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-10-31T07:59:56.123+0700] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-10-31T07:59:56.134+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-30T23:00:00+00:00 [queued]>
[2025-10-31T07:59:56.138+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-30T23:00:00+00:00 [queued]>
[2025-10-31T07:59:56.138+0700] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-10-31T07:59:56.145+0700] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): retrain_model> on 2025-10-30 23:00:00+00:00
[2025-10-31T07:59:56.151+0700] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=13195) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-10-31T07:59:56.152+0700] {standard_task_runner.py:63} INFO - Started process 13221 to run task
[2025-10-31T07:59:56.153+0700] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'absa_streaming_lifecycle_demo11', 'retrain_model', 'scheduled__2025-10-30T23:00:00+00:00', '--job-id', '26', '--raw', '--subdir', 'DAGS_FOLDER/absa_streaming_lifecycle_dag1.py', '--cfg-path', '/tmp/tmpvl5mxrp7']
[2025-10-31T07:59:56.154+0700] {standard_task_runner.py:91} INFO - Job 26: Subtask retrain_model
[2025-10-31T07:59:56.177+0700] {task_command.py:426} INFO - Running <TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-30T23:00:00+00:00 [running]> on host b701d4cdc1cf
[2025-10-31T07:59:56.230+0700] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='absa_streaming_lifecycle_demo11' AIRFLOW_CTX_TASK_ID='retrain_model' AIRFLOW_CTX_EXECUTION_DATE='2025-10-30T23:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-30T23:00:00+00:00'
[2025-10-31T07:59:56.231+0700] {taskinstance.py:430} INFO - ::endgroup::
[2025-10-31T07:59:56.232+0700] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T07:59:56.233+0700] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'bash -c "set -euo pipefail; python /opt/***/projects/absa_streaming/scripts/retrain.py"']
[2025-10-31T07:59:56.244+0700] {subprocess.py:86} INFO - Output:
[2025-10-31T08:00:05.702+0700] {subprocess.py:93} INFO - /home/***/.local/lib/python3.12/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
[2025-10-31T08:00:05.703+0700] {subprocess.py:93} INFO -   warnings.warn(
[2025-10-31T08:02:32.661+0700] {job.py:218} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/jobs/job.py", line 213, in heartbeat
    heartbeat_callback(session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/jobs/local_task_job_runner.py", line 258, in heartbeat_callback
    self.task_instance.refresh_from_db()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1818, in refresh_from_db
    _refresh_from_db(task_instance=self, session=session, lock_for_update=lock_for_update)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 510, in _refresh_from_db
    ti = TaskInstance.get_task_instance(
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1804, in get_task_instance
    return query.one_or_none()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2850, in one_or_none
    return self._iter().one_or_none()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-31T08:03:03.446+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:04:31.643+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:06:09.796+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:08:24.831+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:12:34.466+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:15:07.805+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:16:46.790+0700] {local_task_job_runner.py:310} WARNING - State of this instance has been externally set to restarting. Terminating instance.
[2025-10-31T08:16:46.790+0700] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-10-31T08:16:46.906+0700] {process_utils.py:132} INFO - Sending 15 to group 13221. PIDs of all processes in the group: [13222, 13221]
[2025-10-31T08:16:46.969+0700] {process_utils.py:87} INFO - Sending the signal 15 to group 13221
[2025-10-31T08:16:47.238+0700] {taskinstance.py:2607} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-10-31T08:16:47.279+0700] {subprocess.py:104} INFO - Sending SIGTERM signal to process group
[2025-10-31T08:16:47.283+0700] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-10-31T08:16:47.333+0700] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 460, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 234, in execute
    result = self.subprocess_hook.run_command(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/hooks/subprocess.py", line 91, in run_command
    for raw_line in iter(self.sub_process.stdout.readline, b""):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 2609, in signal_handler
    raise AirflowTaskTerminated("Task received SIGTERM signal")
airflow.exceptions.AirflowTaskTerminated: Task received SIGTERM signal
[2025-10-31T08:16:47.365+0700] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=absa_streaming_lifecycle_demo11, task_id=retrain_model, execution_date=20251030T230000, start_date=20251031T005956, end_date=20251031T011647
[2025-10-31T08:16:47.503+0700] {process_utils.py:80} INFO - Process psutil.Process(pid=13221, status='terminated', exitcode=2, started='07:59:56') (13221) terminated with exit code 2
[2025-10-31T08:16:47.598+0700] {process_utils.py:80} INFO - Process psutil.Process(pid=13222, status='terminated', started='07:59:56') (13222) terminated with exit code None
