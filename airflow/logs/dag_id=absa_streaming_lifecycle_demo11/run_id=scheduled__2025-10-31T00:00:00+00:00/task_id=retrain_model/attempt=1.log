[2025-10-31T08:00:09.686+0700] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-10-31T08:00:09.715+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-31T00:00:00+00:00 [queued]>
[2025-10-31T08:00:09.722+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-31T00:00:00+00:00 [queued]>
[2025-10-31T08:00:09.722+0700] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-10-31T08:00:09.734+0700] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): retrain_model> on 2025-10-31 00:00:00+00:00
[2025-10-31T08:00:09.741+0700] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=13500) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-10-31T08:00:09.742+0700] {standard_task_runner.py:63} INFO - Started process 13696 to run task
[2025-10-31T08:00:09.743+0700] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'absa_streaming_lifecycle_demo11', 'retrain_model', 'scheduled__2025-10-31T00:00:00+00:00', '--job-id', '30', '--raw', '--subdir', 'DAGS_FOLDER/absa_streaming_lifecycle_dag1.py', '--cfg-path', '/tmp/tmp_fy9jfwx']
[2025-10-31T08:00:09.745+0700] {standard_task_runner.py:91} INFO - Job 30: Subtask retrain_model
[2025-10-31T08:00:09.787+0700] {task_command.py:426} INFO - Running <TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-31T00:00:00+00:00 [running]> on host b701d4cdc1cf
[2025-10-31T08:00:09.877+0700] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='absa_streaming_lifecycle_demo11' AIRFLOW_CTX_TASK_ID='retrain_model' AIRFLOW_CTX_EXECUTION_DATE='2025-10-31T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-31T00:00:00+00:00'
[2025-10-31T08:00:09.878+0700] {taskinstance.py:430} INFO - ::endgroup::
[2025-10-31T08:00:09.879+0700] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T08:00:09.880+0700] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'bash -c "set -euo pipefail; python /opt/***/projects/absa_streaming/scripts/retrain.py"']
[2025-10-31T08:00:09.895+0700] {subprocess.py:86} INFO - Output:
[2025-10-31T08:02:30.310+0700] {job.py:218} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/jobs/job.py", line 213, in heartbeat
    heartbeat_callback(session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/jobs/local_task_job_runner.py", line 258, in heartbeat_callback
    self.task_instance.refresh_from_db()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1818, in refresh_from_db
    _refresh_from_db(task_instance=self, session=session, lock_for_update=lock_for_update)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 510, in _refresh_from_db
    ti = TaskInstance.get_task_instance(
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 115, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 1804, in get_task_instance
    return query.one_or_none()
           ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2850, in one_or_none
    return self._iter().one_or_none()
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2025-10-31T08:03:06.109+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:04:31.643+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:06:09.796+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:08:17.256+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:12:00.905+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:14:20.661+0700] {job.py:226} ERROR - Job heartbeat failed with error. Scheduler is in unhealthy state
[2025-10-31T08:15:39.572+0700] {subprocess.py:93} INFO - /home/***/.local/lib/python3.12/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
[2025-10-31T08:15:39.586+0700] {subprocess.py:93} INFO -   warnings.warn(
[2025-10-31T08:16:30.822+0700] {local_task_job_runner.py:310} WARNING - State of this instance has been externally set to restarting. Terminating instance.
[2025-10-31T08:16:30.825+0700] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-10-31T08:16:30.828+0700] {process_utils.py:132} INFO - Sending 15 to group 13696. PIDs of all processes in the group: [13698, 13696]
[2025-10-31T08:16:30.829+0700] {process_utils.py:87} INFO - Sending the signal 15 to group 13696
[2025-10-31T08:16:30.829+0700] {taskinstance.py:2607} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-10-31T08:16:30.830+0700] {subprocess.py:104} INFO - Sending SIGTERM signal to process group
[2025-10-31T08:16:30.832+0700] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-10-31T08:16:30.848+0700] {taskinstance.py:2890} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 460, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/bash.py", line 234, in execute
    result = self.subprocess_hook.run_command(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/hooks/subprocess.py", line 91, in run_command
    for raw_line in iter(self.sub_process.stdout.readline, b""):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 2609, in signal_handler
    raise AirflowTaskTerminated("Task received SIGTERM signal")
airflow.exceptions.AirflowTaskTerminated: Task received SIGTERM signal
[2025-10-31T08:16:30.856+0700] {taskinstance.py:1205} INFO - Marking task as UP_FOR_RETRY. dag_id=absa_streaming_lifecycle_demo11, task_id=retrain_model, execution_date=20251031T000000, start_date=20251031T010009, end_date=20251031T011630
[2025-10-31T08:16:31.162+0700] {process_utils.py:80} INFO - Process psutil.Process(pid=13698, status='terminated', started='08:00:09') (13698) terminated with exit code None
[2025-10-31T08:16:31.163+0700] {process_utils.py:80} INFO - Process psutil.Process(pid=13696, status='terminated', exitcode=2, started='08:00:09') (13696) terminated with exit code 2
[2025-10-31T08:19:28.411+0700] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-10-31T08:19:28.425+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-31T00:00:00+00:00 [queued]>
[2025-10-31T08:19:28.429+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-31T00:00:00+00:00 [queued]>
[2025-10-31T08:19:28.429+0700] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-10-31T08:19:28.438+0700] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): retrain_model> on 2025-10-31 00:00:00+00:00
[2025-10-31T08:19:28.444+0700] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=14882) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-10-31T08:19:28.445+0700] {standard_task_runner.py:63} INFO - Started process 14885 to run task
[2025-10-31T08:19:28.446+0700] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'absa_streaming_lifecycle_demo11', 'retrain_model', 'scheduled__2025-10-31T00:00:00+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/absa_streaming_lifecycle_dag1.py', '--cfg-path', '/tmp/tmp8e4u0igo']
[2025-10-31T08:19:28.447+0700] {standard_task_runner.py:91} INFO - Job 33: Subtask retrain_model
[2025-10-31T08:19:28.474+0700] {task_command.py:426} INFO - Running <TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-31T00:00:00+00:00 [running]> on host b701d4cdc1cf
[2025-10-31T08:19:28.528+0700] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='absa_streaming_lifecycle_demo11' AIRFLOW_CTX_TASK_ID='retrain_model' AIRFLOW_CTX_EXECUTION_DATE='2025-10-31T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-31T00:00:00+00:00'
[2025-10-31T08:19:28.530+0700] {taskinstance.py:430} INFO - ::endgroup::
[2025-10-31T08:19:28.530+0700] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T08:19:28.531+0700] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'bash -c "set -euo pipefail; python /opt/***/projects/absa_streaming/scripts/retrain.py"']
[2025-10-31T08:19:28.544+0700] {subprocess.py:86} INFO - Output:
[2025-10-31T08:19:44.254+0700] {subprocess.py:93} INFO - /home/***/.local/lib/python3.12/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
[2025-10-31T08:19:44.255+0700] {subprocess.py:93} INFO -   warnings.warn(
[2025-10-31T08:22:02.334+0700] {subprocess.py:93} INFO - /opt/***/projects/absa_streaming/scripts/retrain.py:428: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
[2025-10-31T08:22:02.341+0700] {subprocess.py:93} INFO -   "saved_at": datetime.utcnow().isoformat(),
[2025-10-31T08:22:03.134+0700] {subprocess.py:93} INFO - ==> Kh·ªüi ƒë·ªông retrain.py (train=TRAIN; VAL ch·ªâ h·ªó tr·ª£; quy·∫øt ƒë·ªãnh d·ª±a tr√™n TEST cu·ªëi).
[2025-10-31T08:22:03.135+0700] {subprocess.py:93} INFO - [Info] F1_macro t·ªët nh·∫•t ƒë√£ log: 0.0000
[2025-10-31T08:22:03.135+0700] {subprocess.py:93} INFO - [Info] VAL: /opt/***/projects/absa_streaming/data/val_data.csv (rows=936)
[2025-10-31T08:22:03.135+0700] {subprocess.py:93} INFO - [INFO] PostgreSQL r·ªóng ‚Äî ch∆∞a c√≥ model retrain n√†o, d√πng model m·∫∑c ƒë·ªãnh.
[2025-10-31T08:22:03.135+0700] {subprocess.py:93} INFO - [INFO] üîÅ D√πng model m·∫∑c ƒë·ªãnh: /opt/***/models/best_absa_hardshare.pt
[2025-10-31T08:22:03.136+0700] {subprocess.py:93} INFO - [INFO] Model ƒëang train tr√™n thi·∫øt b·ªã: cuda
[2025-10-31T08:22:03.136+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T08:22:03.136+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T08:22:03.136+0700] {subprocess.py:93} INFO - [Epoch 2] time=30.9s | train_loss=0.2806 | VAL: loss=0.2431 acc=0.9192 f1_macro=0.6724 pre_macro=0.8400 rec_macro=0.6555
[2025-10-31T08:22:03.136+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T08:22:03.137+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T08:22:03.137+0700] {subprocess.py:93} INFO - [Epoch 4] time=32.4s | train_loss=0.1527 | VAL: loss=0.1976 acc=0.9320 f1_macro=0.8230 pre_macro=0.8428 rec_macro=0.8080
[2025-10-31T08:22:03.137+0700] {subprocess.py:93} INFO - [FINAL TEST] loss=0.2004 | acc=0.9334 | f1_macro=0.8243 | pre_macro=0.8392 | rec_macro=0.8125
[2025-10-31T08:22:03.138+0700] {subprocess.py:93} INFO - [SAVE] B·∫Øt ƒë·∫ßu l∆∞u model v√†o: /opt/***/models/newer_models/best_absa_2/model.pt
[2025-10-31T08:22:03.138+0700] {subprocess.py:93} INFO - [SAVE] ƒê√£ l∆∞u file .pt v√† .json th√†nh c√¥ng.
[2025-10-31T08:22:03.138+0700] {subprocess.py:93} INFO - [SAVE] TEST f1_macro improved (0.0000 -> 0.8243). ƒê√£ c·∫≠p nh·∫≠t DB. Saved to: /opt/***/models/newer_models/best_absa_2
[2025-10-31T08:22:03.138+0700] {subprocess.py:93} INFO - ==> Retrain ho√†n t·∫•t.
[2025-10-31T08:22:04.254+0700] {subprocess.py:97} INFO - Command exited with return code 0
[2025-10-31T08:22:04.259+0700] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-10-31T08:22:04.303+0700] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=absa_streaming_lifecycle_demo11, task_id=retrain_model, execution_date=20251031T000000, start_date=20251031T011928, end_date=20251031T012204
[2025-10-31T08:22:04.371+0700] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-10-31T08:22:04.496+0700] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T08:22:04.510+0700] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-10-31T08:30:48.596+0700] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-10-31T08:30:48.615+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-31T00:00:00+00:00 [queued]>
[2025-10-31T08:30:48.621+0700] {taskinstance.py:2073} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-31T00:00:00+00:00 [queued]>
[2025-10-31T08:30:48.622+0700] {taskinstance.py:2303} INFO - Starting attempt 1 of 2
[2025-10-31T08:30:48.633+0700] {taskinstance.py:2327} INFO - Executing <Task(BashOperator): retrain_model> on 2025-10-31 00:00:00+00:00
[2025-10-31T08:30:48.642+0700] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=16888) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-10-31T08:30:48.643+0700] {standard_task_runner.py:63} INFO - Started process 16989 to run task
[2025-10-31T08:30:48.644+0700] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'absa_streaming_lifecycle_demo11', 'retrain_model', 'scheduled__2025-10-31T00:00:00+00:00', '--job-id', '38', '--raw', '--subdir', 'DAGS_FOLDER/absa_streaming_lifecycle_dag1.py', '--cfg-path', '/tmp/tmp_1q5asvw']
[2025-10-31T08:30:48.646+0700] {standard_task_runner.py:91} INFO - Job 38: Subtask retrain_model
[2025-10-31T08:30:48.684+0700] {task_command.py:426} INFO - Running <TaskInstance: absa_streaming_lifecycle_demo11.retrain_model scheduled__2025-10-31T00:00:00+00:00 [running]> on host b701d4cdc1cf
[2025-10-31T08:30:48.756+0700] {taskinstance.py:2644} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='absa_streaming_lifecycle_demo11' AIRFLOW_CTX_TASK_ID='retrain_model' AIRFLOW_CTX_EXECUTION_DATE='2025-10-31T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-10-31T00:00:00+00:00'
[2025-10-31T08:30:48.758+0700] {taskinstance.py:430} INFO - ::endgroup::
[2025-10-31T08:30:48.759+0700] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-10-31T08:30:48.759+0700] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'bash -c "set -euo pipefail; python /opt/***/projects/absa_streaming/scripts/retrain.py"']
[2025-10-31T08:30:48.775+0700] {subprocess.py:86} INFO - Output:
[2025-10-31T08:31:00.909+0700] {subprocess.py:93} INFO - /home/***/.local/lib/python3.12/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
[2025-10-31T08:31:00.910+0700] {subprocess.py:93} INFO -   warnings.warn(
[2025-10-31T08:33:16.650+0700] {subprocess.py:93} INFO - /opt/***/projects/absa_streaming/scripts/retrain.py:439: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
[2025-10-31T08:33:21.833+0700] {subprocess.py:93} INFO -   "saved_at": datetime.utcnow().isoformat(),
[2025-10-31T08:33:21.834+0700] {subprocess.py:93} INFO - ==> Kh·ªüi ƒë·ªông retrain.py (train=TRAIN; VAL ch·ªâ h·ªó tr·ª£; quy·∫øt ƒë·ªãnh d·ª±a tr√™n TEST cu·ªëi).
[2025-10-31T08:33:21.834+0700] {subprocess.py:93} INFO - [Info] F1_macro t·ªët nh·∫•t ƒë√£ log: 0.0000
[2025-10-31T08:33:21.834+0700] {subprocess.py:93} INFO - [Info] VAL: /opt/***/projects/absa_streaming/data/val_data.csv (rows=936)
[2025-10-31T08:33:21.895+0700] {subprocess.py:93} INFO - [INFO] PostgreSQL r·ªóng ‚Äî ch∆∞a c√≥ model retrain n√†o, d√πng model m·∫∑c ƒë·ªãnh.
[2025-10-31T08:33:21.977+0700] {subprocess.py:93} INFO - [INFO] üîÅ D√πng model m·∫∑c ƒë·ªãnh: /opt/***/models/best_absa_hardshare.pt
[2025-10-31T08:33:21.977+0700] {subprocess.py:93} INFO - [INFO] Model ƒëang train tr√™n thi·∫øt b·ªã: cuda
[2025-10-31T08:33:21.978+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T08:33:21.978+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T08:33:21.978+0700] {subprocess.py:93} INFO - [Epoch 2] time=30.9s | train_loss=nan | VAL: loss=nan acc=0.8580 f1_macro=0.7348 pre_macro=0.8183 rec_macro=0.6907
[2025-10-31T08:33:21.978+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T08:33:21.978+0700] {subprocess.py:93} INFO - B·∫Øt ƒë·∫ßu train 1 epoch
[2025-10-31T08:33:21.978+0700] {subprocess.py:93} INFO - [Epoch 4] time=32.2s | train_loss=nan | VAL: loss=nan acc=0.8979 f1_macro=0.8318 pre_macro=0.8457 rec_macro=0.8192
[2025-10-31T08:33:21.978+0700] {subprocess.py:93} INFO - [FINAL TEST] loss=nan | acc=0.8905 | f1_macro=0.8162 | pre_macro=0.8270 | rec_macro=0.8062
[2025-10-31T08:33:21.978+0700] {subprocess.py:93} INFO - [SAVE] B·∫Øt ƒë·∫ßu l∆∞u model v√†o: /opt/***/models/newer_models/best_absa_2/model.pt
[2025-10-31T08:33:21.978+0700] {subprocess.py:93} INFO - [SAVE] ƒê√£ l∆∞u file .pt v√† .json th√†nh c√¥ng.
[2025-10-31T08:33:21.979+0700] {subprocess.py:93} INFO - [SAVE] TEST f1_macro improved (0.0000 -> 0.8162). ƒê√£ c·∫≠p nh·∫≠t DB. Saved to: /opt/***/models/newer_models/best_absa_2
[2025-10-31T08:33:21.979+0700] {subprocess.py:93} INFO - ==> Retrain ho√†n t·∫•t.
[2025-10-31T08:33:23.044+0700] {subprocess.py:97} INFO - Command exited with return code 0
[2025-10-31T08:33:23.046+0700] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-10-31T08:33:23.098+0700] {taskinstance.py:1205} INFO - Marking task as SUCCESS. dag_id=absa_streaming_lifecycle_demo11, task_id=retrain_model, execution_date=20251031T000000, start_date=20251031T013048, end_date=20251031T013323
[2025-10-31T08:33:23.164+0700] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-10-31T08:33:23.221+0700] {taskinstance.py:3482} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-10-31T08:33:23.241+0700] {local_task_job_runner.py:222} INFO - ::endgroup::
