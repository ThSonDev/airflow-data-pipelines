{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab054074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.3.0 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy==1.26.4 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas==2.2.2 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn==1.4.2 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: filelock in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (4.15.0)\n",
      "Requirement already satisfied: sympy in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from scikit-learn==1.4.2) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from scikit-learn==1.4.2) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from scikit-learn==1.4.2) (3.6.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.8.93)\n",
      "Requirement already satisfied: six>=1.5 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from jinja2->torch==2.3.0) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages (from sympy->torch==2.3.0) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.3.0 numpy==1.26.4 pandas==2.2.2 scikit-learn==1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e71cebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.3.0+cu121\n",
      "numpy: 1.26.4\n",
      "pandas: 2.2.2\n",
      "scikit-learn: 1.4.2\n",
      "Sử dụng thiết bị: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np, pandas as pd, sklearn\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Sử dụng thiết bị: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69ab531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train_df:  (8424, 9)\n",
      "Shape test_df:  (2340, 9)\n",
      "Shape val_df:  (936, 9)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../airflow/projects/absa_streaming/data/train_data.csv\", sep=\",\", header=0, encoding='utf-8')\n",
    "test_df = pd.read_csv(\"../airflow/projects/absa_streaming/data/test_data.csv\", sep=\",\", header=0, encoding='utf-8')\n",
    "val_df = pd.read_csv(\"../airflow/projects/absa_streaming/data/val_data.csv\", sep=\",\", header=0, encoding='utf-8')\n",
    "\n",
    "print(\"Shape train_df: \", train_df.shape)\n",
    "print(\"Shape test_df: \", test_df.shape)\n",
    "print(\"Shape val_df: \",val_df.shape)\n",
    "\n",
    "COMMENT_COLUMN_NAME = 'Review'\n",
    "ASPECT_COLUMNS = ['Price', 'Shipping', 'Outlook', 'Quality', 'Size', 'Shop_Service', 'General', 'Others']\n",
    "# 0: Negative\n",
    "# 1: Positive\n",
    "# 2: Neutral\n",
    "# -1: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "758cc75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    giày hơi có mùi nồng lưu ý đôi la không phải đ...\n",
      "1    hàng về đẹp lắm nha ship thân thiện đi giày vừ...\n",
      "2                          hàng ôk nên mua dày rất đẹp\n",
      "3    bun gti gửi oke sớ ơ đi sidbd bởi đi được đạn ...\n",
      "4    màu đẹp giống trong hình mọi người nên mua nha...\n",
      "5    chất lượng phù hợp với giá tiền đi đúng sz như...\n",
      "6    giày trượt lắm huhu đánh giải trường mà trượt ...\n",
      "7    tr ơi dép đẹp vs dth lắm nha vs giá này mà chấ...\n",
      "8                                   cũng tạm được thoi\n",
      "9                   shop hỗ trợ rất tốt mn nên mua nhé\n",
      "Name: clean_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "REMOVE_TONE = False\n",
    "REMOVE_NOISE = True\n",
    "\n",
    "def remove_vietnamese_tone(text):\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = re.sub(r'[\\u0300-\\u036f]', '', text)\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "    return text\n",
    "\n",
    "def remove_non_vietnamese_chars(text):\n",
    "    return re.sub(\n",
    "        r\"[^a-zàáạảãăắằặẳẵâầấậẩẫèéẹẻẽêềếệểễ\"\n",
    "        r\"ìíịỉĩòóọỏõôồốộổỗơờớợởỡùúụủũưừứựửữ\"\n",
    "        r\"ỳýỵỷỹđ0-9\\s]\",\n",
    "        \" \",\n",
    "        text\n",
    "    )\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower().strip()\n",
    "\n",
    "    if REMOVE_TONE:\n",
    "        text = remove_vietnamese_tone(text)\n",
    "\n",
    "    if REMOVE_NOISE:\n",
    "        text = remove_non_vietnamese_chars(text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "train_df[\"clean_text\"] = train_df[\"Review\"].apply(clean).apply(lambda x: \" \".join(x.split()))\n",
    "val_df[\"clean_text\"]   = val_df[\"Review\"].apply(clean).apply(lambda x: \" \".join(x.split()))\n",
    "test_df[\"clean_text\"]  = test_df[\"Review\"].apply(clean).apply(lambda x: \" \".join(x.split()))\n",
    "\n",
    "print(test_df[\"clean_text\"].head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79c08905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số từ vựng (unique words): 6,668\n",
      "10 từ phổ biến nhất:\n",
      "giày            : 4752\n",
      "đẹp             : 4153\n",
      "hàng            : 3737\n",
      "mua             : 2684\n",
      "giao            : 2492\n",
      "shop            : 2416\n",
      "nên             : 2296\n",
      "giá             : 1992\n",
      "nhanh           : 1973\n",
      "đi              : 1867\n",
      "Vocab size: 6002\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# Tạo Counter để đếm tần suất từ\n",
    "counter = Counter()\n",
    "\n",
    "# Duyệt qua từng dòng trong cột clean_text\n",
    "for text in train_df[\"clean_text\"]:\n",
    "    counter.update(text.split())\n",
    "\n",
    "# Tổng số từ khác nhau\n",
    "total_vocab = len(counter)\n",
    "\n",
    "# Top 10 từ phổ biến nhất \n",
    "most_common = counter.most_common(10)\n",
    "\n",
    "print(f\"Tổng số từ vựng (unique words): {total_vocab:,}\")\n",
    "print(\"10 từ phổ biến nhất:\")\n",
    "for word, freq in most_common:\n",
    "    print(f\"{word:15} : {freq}\")\n",
    "\n",
    "MAX_VOCAB = 6000\n",
    "vocab = {w: i+2 for i, (w, _) in enumerate(counter.most_common(MAX_VOCAB))}\n",
    "vocab[\"<PAD>\"] = 0\n",
    "vocab[\"<UNK>\"] = 1\n",
    "\n",
    "print(f\"Vocab size: {len(vocab)}\")\n",
    "\n",
    "with open(\"../airflow/models/vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "633c70df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [tensor(2), tensor(3), tensor(11), tensor(57),...\n",
      "1    [tensor(21), tensor(296), tensor(281), tensor(...\n",
      "2    [tensor(31), tensor(44), tensor(34), tensor(18...\n",
      "3    [tensor(21), tensor(76), tensor(22), tensor(25...\n",
      "4    [tensor(8), tensor(5), tensor(12), tensor(58),...\n",
      "Name: encoded, dtype: object\n",
      "0    [tensor(4), tensor(3), tensor(119), tensor(20)...\n",
      "1    [tensor(564), tensor(427), tensor(300), tensor...\n",
      "2    [tensor(6), tensor(10), tensor(2), tensor(3), ...\n",
      "3    [tensor(183), tensor(1794), tensor(200), tenso...\n",
      "4    [tensor(194), tensor(90), tensor(12), tensor(1...\n",
      "Name: encoded, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def encode(text):\n",
    "    return torch.tensor([vocab.get(t, 1) for t in text.split()], dtype=torch.long)\n",
    "\n",
    "train_df[\"encoded\"] = train_df[\"clean_text\"].apply(encode)\n",
    "val_df[\"encoded\"] = val_df[\"clean_text\"].apply(encode)\n",
    "test_df[\"encoded\"] = test_df[\"clean_text\"].apply(encode)\n",
    "print(train_df[\"encoded\"].head())\n",
    "print(val_df[\"encoded\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3daa656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.texts = df[\"encoded\"].tolist()\n",
    "        self.labels = df[ASPECT_COLUMNS].values\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Lấy nhãn gốc (ví dụ: [-1, 0, 1, 2])\n",
    "        original_labels = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        # Ánh xạ nhãn: cộng 1 vào tất cả\n",
    "        # -1 (None)   -> 0\n",
    "        #  0 (Neg)    -> 1\n",
    "        #  1 (Pos)    -> 2\n",
    "        #  2 (Neu)    -> 3\n",
    "        mapped_labels = original_labels + 1\n",
    "        \n",
    "        return self.texts[idx], mapped_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    texts_padded = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "    return texts_padded, torch.stack(labels)\n",
    "\n",
    "train_loader = DataLoader(ReviewDataset(train_df), batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(ReviewDataset(val_df), batch_size=64, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(ReviewDataset(test_df), batch_size=64, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f393238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 0.9069 | Val Loss: 0.6845\n",
      "Epoch 2/100 | Train Loss: 0.6977 | Val Loss: 0.6107\n",
      "Epoch 3/100 | Train Loss: 0.6219 | Val Loss: 0.5546\n",
      "Epoch 4/100 | Train Loss: 0.5719 | Val Loss: 0.5125\n",
      "Epoch 5/100 | Train Loss: 0.5333 | Val Loss: 0.4792\n",
      "Epoch 6/100 | Train Loss: 0.4971 | Val Loss: 0.4533\n",
      "Epoch 7/100 | Train Loss: 0.4703 | Val Loss: 0.4325\n",
      "Epoch 8/100 | Train Loss: 0.4470 | Val Loss: 0.4162\n",
      "Epoch 9/100 | Train Loss: 0.4305 | Val Loss: 0.4043\n",
      "Epoch 10/100 | Train Loss: 0.4118 | Val Loss: 0.3906\n",
      "\n",
      "Epoch 10: Macro F1 = 0.5042 | Balanced Acc = 0.4701\n",
      "\n",
      "Epoch 11/100 | Train Loss: 0.3970 | Val Loss: 0.3794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 | Train Loss: 0.3835 | Val Loss: 0.3719\n",
      "Epoch 13/100 | Train Loss: 0.3704 | Val Loss: 0.3623\n",
      "Epoch 14/100 | Train Loss: 0.3620 | Val Loss: 0.3567\n",
      "Epoch 15/100 | Train Loss: 0.3487 | Val Loss: 0.3516\n",
      "Epoch 16/100 | Train Loss: 0.3388 | Val Loss: 0.3462\n",
      "Epoch 17/100 | Train Loss: 0.3301 | Val Loss: 0.3407\n",
      "Epoch 18/100 | Train Loss: 0.3202 | Val Loss: 0.3368\n",
      "Epoch 19/100 | Train Loss: 0.3110 | Val Loss: 0.3348\n",
      "Epoch 20/100 | Train Loss: 0.3047 | Val Loss: 0.3298\n",
      "\n",
      "Epoch 20: Macro F1 = 0.6352 | Balanced Acc = 0.5747\n",
      "\n",
      "Epoch 21/100 | Train Loss: 0.2973 | Val Loss: 0.3292\n",
      "Epoch 22/100 | Train Loss: 0.2885 | Val Loss: 0.3253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 | Train Loss: 0.2812 | Val Loss: 0.3237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 | Train Loss: 0.2734 | Val Loss: 0.3206\n",
      "Epoch 25/100 | Train Loss: 0.2682 | Val Loss: 0.3202\n",
      "Epoch 26/100 | Train Loss: 0.2605 | Val Loss: 0.3182\n",
      "Epoch 27/100 | Train Loss: 0.2555 | Val Loss: 0.3165\n",
      "Epoch 28/100 | Train Loss: 0.2504 | Val Loss: 0.3173\n",
      "Epoch 29/100 | Train Loss: 0.2436 | Val Loss: 0.3174\n",
      "Epoch 30/100 | Train Loss: 0.2368 | Val Loss: 0.3189\n",
      "\n",
      "Epoch 30: Macro F1 = 0.6753 | Balanced Acc = 0.6152\n",
      "\n",
      "Epoch 31/100 | Train Loss: 0.2325 | Val Loss: 0.3155\n",
      "Epoch 32/100 | Train Loss: 0.2259 | Val Loss: 0.3155\n",
      "Epoch 33/100 | Train Loss: 0.2221 | Val Loss: 0.3172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 | Train Loss: 0.2148 | Val Loss: 0.3165\n",
      "Epoch 35/100 | Train Loss: 0.2114 | Val Loss: 0.3182\n",
      "Epoch 36/100 | Train Loss: 0.2070 | Val Loss: 0.3192\n",
      "Epoch 37/100 | Train Loss: 0.2007 | Val Loss: 0.3198\n",
      "Epoch 38/100 | Train Loss: 0.1975 | Val Loss: 0.3209\n",
      "Epoch 39/100 | Train Loss: 0.1941 | Val Loss: 0.3213\n",
      "Epoch 40/100 | Train Loss: 0.1893 | Val Loss: 0.3207\n",
      "\n",
      "Epoch 40: Macro F1 = 0.6954 | Balanced Acc = 0.6423\n",
      "\n",
      "Epoch 41/100 | Train Loss: 0.1842 | Val Loss: 0.3229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 | Train Loss: 0.1788 | Val Loss: 0.3274\n",
      "Epoch 43/100 | Train Loss: 0.1767 | Val Loss: 0.3270\n",
      "Epoch 44/100 | Train Loss: 0.1761 | Val Loss: 0.3308\n",
      "Epoch 45/100 | Train Loss: 0.1690 | Val Loss: 0.3285\n",
      "Epoch 46/100 | Train Loss: 0.1663 | Val Loss: 0.3311\n",
      "Epoch 47/100 | Train Loss: 0.1606 | Val Loss: 0.3315\n",
      "Epoch 48/100 | Train Loss: 0.1587 | Val Loss: 0.3327\n",
      "Epoch 49/100 | Train Loss: 0.1546 | Val Loss: 0.3398\n",
      "Epoch 50/100 | Train Loss: 0.1511 | Val Loss: 0.3372\n",
      "\n",
      "Epoch 50: Macro F1 = 0.7010 | Balanced Acc = 0.6520\n",
      "\n",
      "Epoch 51/100 | Train Loss: 0.1489 | Val Loss: 0.3392\n",
      "⏹ Early stopping at epoch 51\n",
      "Training complete. Best model saved to cnn_best.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 100\n",
    "EMBED_DIM = 128\n",
    "NUM_FILTERS = 192 # Xấp xỉ với embed dim, lớn hơn thì mạnh hơn\n",
    "PATIENCE = 20                 # số epoch không cải thiện thì dừng\n",
    "EVAL_EVERY = 10               # tính F1/Balanced Acc mỗi 5 epoch\n",
    "WORD_WINDOW = 5\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# MODEL DEFINITION\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_labels):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.conv = nn.Conv1d(embed_dim, NUM_FILTERS, kernel_size=WORD_WINDOW, padding=int(WORD_WINDOW // 2))\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.shared_dense = nn.Linear(NUM_FILTERS, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        #self.fc = nn.Linear(NUM_FILTERS, num_labels * NUM_CLASSES) # kiến trúc cũ, 8 aspects dùng chung \n",
    "\n",
    "        self.output_heads = nn.ModuleList([ # kiến trúc mới, mỗi aspects riêng\n",
    "            nn.Linear(128, NUM_CLASSES) for _ in range(num_labels)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).permute(0, 2, 1)\n",
    "        x = torch.relu(self.conv(x))\n",
    "        x = self.pool(x).squeeze(2)\n",
    "\n",
    "        x = torch.relu(self.shared_dense(x)) # Cho qua lớp Dense(128)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "\n",
    "        # return self.fc(x).view(-1, len(ASPECT_COLUMNS), NUM_CLASSES) # kiến trúc cũ\n",
    "        \n",
    "        # ở dưới là kiến trúc mới\n",
    "        outputs = []\n",
    "        for head in self.output_heads:\n",
    "            outputs.append(head(x))\n",
    "            \n",
    "        # Xếp chồng các output lại\n",
    "        # -> Shape: [batch, 8, 4]\n",
    "        return torch.stack(outputs, dim=1)\n",
    "\n",
    "\n",
    "# INIT\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TextCNN(vocab_size=len(vocab), embed_dim=EMBED_DIM, num_labels=len(ASPECT_COLUMNS)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# TRAINING LOOP\n",
    "best_val_loss = float('inf')\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # --- TRAIN ---\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        preds_flat = outputs.view(-1, NUM_CLASSES) \n",
    "        labels_flat = y_batch.view(-1)\n",
    "        loss = criterion(preds_flat, labels_flat)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # --- VALIDATION ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "\n",
    "            preds_flat = outputs.view(-1, NUM_CLASSES)\n",
    "            labels_flat = y_batch.view(-1)\n",
    "\n",
    "            loss = criterion(preds_flat, labels_flat)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = outputs.argmax(dim=2).cpu().numpy()\n",
    "            labels = y_batch.cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # --- EARLY STOPPING ---\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        no_improve = 0\n",
    "        torch.save(model.state_dict(), \"../airflow/models/cnn_best.pth\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= PATIENCE:\n",
    "            print(f\"⏹ Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    # --- METRICS ---\n",
    "    if epoch % EVAL_EVERY == 0:\n",
    "        # Flatten 8 label cột để tính chung\n",
    "        y_true = np.array(all_labels).flatten()\n",
    "        y_pred = np.array(all_preds).flatten()\n",
    "\n",
    "        all_known_labels = [0, 1, 2, 3] # 0=None, 1=Neg, 2=Pos, 3=Neu\n",
    "        \n",
    "        # Tính F1 trên cả 4 lớp\n",
    "        macro_f1 = f1_score(y_true, y_pred, average=\"macro\", labels=all_known_labels, zero_division=0)\n",
    "        balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch}: Macro F1 = {macro_f1:.4f} | Balanced Acc = {balanced_acc:.4f}\\n\")\n",
    "\n",
    "print(\"Training complete. Best model saved to cnn_best.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a41c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải mô hình 'cnn_best.pth'...\n",
      "Đang dự đoán trên tập test\n",
      "Đã hoàn tất dự đoán. Bắt đầu tính toán metrics...\n",
      "\n",
      "--- KẾT QUẢ TỔNG QUAN TRÊN TẬP TEST ---\n",
      "Overall Macro F1-Score:    0.6674\n",
      "Overall Balanced Accuracy: 0.6100\n",
      "\n",
      "Bảng chi tiết (sắp xếp theo F1):\n",
      "  - General        : F1 = 0.4523 | Bal. Acc = 0.4097\n",
      "  - Outlook        : F1 = 0.5078 | Bal. Acc = 0.4947\n",
      "  - Price          : F1 = 0.5208 | Bal. Acc = 0.4865\n",
      "  - Shop_Service   : F1 = 0.5315 | Bal. Acc = 0.5041\n",
      "  - Quality        : F1 = 0.5394 | Bal. Acc = 0.5050\n",
      "  - Size           : F1 = 0.6107 | Bal. Acc = 0.5872\n",
      "  - Shipping       : F1 = 0.6743 | Bal. Acc = 0.6665\n",
      "  - Others         : F1 = 0.8402 | Bal. Acc = 0.7921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thsondev/SSD/Code/appbigdata/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "print(\"Đang tải mô hình 'cnn_best.pth'...\")\n",
    "model = TextCNN(vocab_size=len(vocab), embed_dim=EMBED_DIM, num_labels=len(ASPECT_COLUMNS)).to(device)\n",
    "model.load_state_dict(torch.load(\"../airflow/models/cnn_best.pth\", map_location=device))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"Đang dự đoán trên tập test\")\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        outputs = model(X_batch)\n",
    "        preds = outputs.argmax(dim=2) # Shape: (batch_size, 8)\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(y_batch)\n",
    "        \n",
    "# Nối các batch lại thành tensor lớn\n",
    "all_preds_tensor = torch.cat(all_preds, dim=0)\n",
    "all_labels_tensor = torch.cat(all_labels, dim=0)\n",
    "\n",
    "# Chuyển về numpy\n",
    "y_true_all = all_labels_tensor.cpu().numpy() # Shape: (N_samples, 8)\n",
    "y_pred_all = all_preds_tensor.cpu().numpy() # Shape: (N_samples, 8)\n",
    "\n",
    "print(\"Đã hoàn tất dự đoán. Bắt đầu tính toán metrics...\")\n",
    "\n",
    "# Làm phẳng tất cả các aspect để tính 1 chỉ số tổng quan\n",
    "y_true_flat = y_true_all.flatten()\n",
    "y_pred_flat = y_pred_all.flatten()\n",
    "\n",
    "all_known_labels = [0, 1, 2, 3] # 0=None, 1=Neg, 2=Pos, 3=Neu\n",
    "\n",
    "# [PHẦN TÍNH OVERALL METRICS]\n",
    "# BỎ LỌC (MASK)\n",
    "# y_true_flat và y_pred_flat giờ chứa các nhãn [0, 1, 2, 3]\n",
    "\n",
    "overall_f1 = f1_score(y_true_flat, y_pred_flat, average=\"macro\", labels=all_known_labels, zero_division=0)\n",
    "overall_acc = balanced_accuracy_score(y_true_flat, y_pred_flat)\n",
    "\n",
    "print(\"\\n--- KẾT QUẢ TỔNG QUAN TRÊN TẬP TEST ---\")\n",
    "print(f\"Overall Macro F1-Score:    {overall_f1:.4f}\")\n",
    "print(f\"Overall Balanced Accuracy: {overall_acc:.4f}\")\n",
    "\n",
    "# --- 6. Tính toán Metrics CHO TỪNG ASPECT ---\n",
    "aspect_metrics = {}\n",
    "\n",
    "for i, aspect in enumerate(ASPECT_COLUMNS):\n",
    "    y_true_aspect = y_true_all[:, i]\n",
    "    y_pred_aspect = y_pred_all[:, i]\n",
    "    \n",
    "    \n",
    "    if len(y_true_aspect) > 0:\n",
    "        f1 = f1_score(y_true_aspect, y_pred_aspect, average=\"macro\", zero_division=0)\n",
    "        acc = balanced_accuracy_score(y_true_aspect, y_pred_aspect)\n",
    "        aspect_metrics[aspect] = {\"f1\": f1, \"acc\": acc}\n",
    "    else:\n",
    "        aspect_metrics[aspect] = {\"f1\": 0.0, \"acc\": 0.0} # Không có nhãn nào để đánh giá\n",
    "\n",
    "# --- 7. Tìm Aspect Tốt/Tệ Nhất (dựa trên F1-Score) ---\n",
    "# Sắp xếp dict theo F1-score\n",
    "sorted_aspects = sorted(aspect_metrics.items(), key=lambda item: item[1]['f1'])\n",
    "\n",
    "print(\"\\nBảng chi tiết (sắp xếp theo F1):\")\n",
    "for aspect, metrics in sorted_aspects:\n",
    "    print(f\"  - {aspect:15}: F1 = {metrics['f1']:.4f} | Bal. Acc = {metrics['acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e27477e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------\n",
      "REVIEW: \"Giày đẹp lắm shop, giao hàng cũng nhanh nữa, giá rẻ quá.\"\n",
      "  - Price          : POS\n",
      "  - Shipping       : POS\n",
      "  - Outlook        : POS\n",
      "  - Quality        : NONE\n",
      "  - Size           : NONE\n",
      "  - Shop_Service   : NONE\n",
      "  - General        : NONE\n",
      "  - Others         : NONE\n",
      "\n",
      "---------------------------------\n",
      "REVIEW: \"Rất tệ, giày bị hỏng, có mùi hôi và shop không trả lời tin nhắn.\"\n",
      "  - Price          : NONE\n",
      "  - Shipping       : NONE\n",
      "  - Outlook        : NONE\n",
      "  - Quality        : NONE\n",
      "  - Size           : NONE\n",
      "  - Shop_Service   : NEG\n",
      "  - General        : NONE\n",
      "  - Others         : NONE\n",
      "\n",
      "---------------------------------\n",
      "REVIEW: \"Đóng gói bình thường, chất lượng cũng tạm ổn so với giá tiền.\"\n",
      "  - Price          : NONE\n",
      "  - Shipping       : NONE\n",
      "  - Outlook        : NONE\n",
      "  - Quality        : NEU\n",
      "  - Size           : NONE\n",
      "  - Shop_Service   : NEG\n",
      "  - General        : NEU\n",
      "  - Others         : NONE\n",
      "\n",
      "---------------------------------\n",
      "REVIEW: \"Size hơi nhỏ so với mô tả, tôi phải đi đổi lại.\"\n",
      "  - Price          : NONE\n",
      "  - Shipping       : NONE\n",
      "  - Outlook        : NONE\n",
      "  - Quality        : NONE\n",
      "  - Size           : NEG\n",
      "  - Shop_Service   : NONE\n",
      "  - General        : NONE\n",
      "  - Others         : NONE\n"
     ]
    }
   ],
   "source": [
    "custom_reviews = [\n",
    "    \"Giày đẹp lắm shop, giao hàng cũng nhanh nữa, giá rẻ quá.\",\n",
    "    \"Rất tệ, giày bị hỏng, có mùi hôi và shop không trả lời tin nhắn.\",\n",
    "    \"Đóng gói bình thường, chất lượng cũng tạm ổn so với giá tiền.\",\n",
    "    \"Size hơi nhỏ so với mô tả, tôi phải đi đổi lại.\"\n",
    "]\n",
    "\n",
    "prediction_map = {\n",
    "    0: \"NONE\", # Lớp 0 (trước là -1)\n",
    "    1: \"NEG\",   # Lớp 1 (trước là 0)\n",
    "    2: \"POS\",   # Lớp 2 (trước là 1)\n",
    "    3: \"NEU\"    # Lớp 3 (trước là 2)\n",
    "}\n",
    "\n",
    "model = TextCNN(vocab_size=len(vocab), embed_dim=EMBED_DIM, num_labels=len(ASPECT_COLUMNS)).to(device)\n",
    "model.load_state_dict(torch.load(\"../airflow/models/cnn_best.pth\", map_location=device))\n",
    "model.eval() \n",
    "\n",
    "cleaned_texts = [clean(text) for text in custom_reviews]\n",
    "encoded_texts = [encode(text) for text in cleaned_texts]\n",
    "padded_batch = pad_sequence(encoded_texts, batch_first=True, padding_value=0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(padded_batch)\n",
    "    predictions = outputs.argmax(dim=2).cpu().numpy()\n",
    "\n",
    "# In kết quả\n",
    "\n",
    "for i, review in enumerate(custom_reviews):\n",
    "    print(\"\\n---------------------------------\")\n",
    "    print(f\"REVIEW: \\\"{review}\\\"\")\n",
    "    \n",
    "    review_preds = predictions[i] # Lấy mảng 8 dự đoán cho review này\n",
    "    \n",
    "    for j, aspect in enumerate(ASPECT_COLUMNS):\n",
    "        pred_index = review_preds[j] # Lấy dự đoán (0, 1, 2)\n",
    "        pred_string = prediction_map.get(pred_index, \"LỖI\") # Map sang text\n",
    "        \n",
    "        print(f\"  - {aspect:15}: {pred_string}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
